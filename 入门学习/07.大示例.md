接下来我们完整地体会一个简单的服务器程序的设计、编写和迭代。



### 需求

我们要开发的是一个简单的静态文件合并服务器，该服务器需要支持类似以下格式的JS或CSS文件合并请求。

```js
http://assets.example.com/foo/??bar.js,baz.js
```



#### 第一次迭代 -- 满足基本需求

```js
const fs = require('fs')
const http = require('http');
const path = require('path');

const MIME = {
  'css': 'text/css',
  'js': 'application/javascript'
}

// 解析url
// "http://assets.example.com/foo/??bar.js,baz.js" -> bar.js & baz.js [path, mime]
const parseUrl = url => {
  let base
  let pathnames
  let parts

  if (url.indexOf('??') === -1) {
    url = url.replace('/', '/??')
  }

  parts = url.split('??')
  base = parts[0]
  pathnames = parts[1].split(',').map(
    val => path.join(root, base, val)
  )

  return {
    mime: MIME[path.extname(pathnames[0])] || 'text/css',
    pathnames
  }
}

// 合并文件内容
const combineFiles = (pathnames, callback) => {
  const output = []
  const len = pathnames.length

  (function next(i) {
    fs.readFile(pathnames[i], (err, data) => {
      if (i < len) {
        if (err) {
          callback(err)
        } else {
          output.push(data)
          next(i + 1)
        }
      } else {
        callback(null, Buffer.concat(output))
      }
    })
  })(0)
}

// 程序入口
const main = argv => {
  // 可配置项
  const { 
    root = '.', 
    port = 80 
  } = JSON.parse(fs.readFileAsync(argv[0], 'utf-8'))
  
  http.createServer((req, res) => {
    const { url } = req;
    const { mime, pathnames } = parseUrl(root, url);

    combineFiles(pathnames, (err, data) => {
      if (err) {
        res.writeHead(404)
        res.end(err.message)
      } else {
        res.writeHead(200, {
          'Content-Type': mime
        })
      }
    })
  }).listen(port)
}

main(process.argv.slice(2))
```



#### 第二次迭代--服务器性能优化

分析主要的性能问题

第一版代码依次把请求的文件读取到内存中之后，再合并数据和输出响应。这会导致以下两个问题：

1. 当请求的文件比较多比较大时，串行读取文件会比较耗时，从而拉长了服务端响应等待时间。
2. 由于每次响应输出的数据都需要先完整地缓存在内存里，当服务器请求并发数较大时，会有较大的内存开销。

对于第一个问题，很容易想到把读取文件的方式从串行改为并行。但是别这样做，因为对于机械磁盘而言，因为只有一个磁头，尝试并行读取文件只会造成磁头频繁抖动，反而降低IO效率。而对于固态硬盘，虽然的确存在多个并行IO通道，但是对于服务器并行处理的多个请求而言，硬盘已经在做并行IO了，对单个请求采用并行IO无异于拆东墙补西墙。因此，正确的做法不是改用并行IO，而是一边读取文件一边输出响应，把响应输出时机提前至读取第一个文件的时刻。

这样调整后，整个请求处理过程变成下边这样。

```
解析请求 -> 检查文件是否存在 -> 输出响应头 -> 读取和输出a.js -> 读取和输出b.js -> 读取和输出c.js
```

调整部分函数：

```js
const outputFiles = (pathnames, writer) => {
  (function next(i, len) {
    if (i < len) {
      const reader = fs.createReadStream(pathnames[i])
      reader.pipe(writer, { end: false })
      reader.on('end', () => {
        next(i + 1, len)
      })
    } else {
      writer.end()
    }
  })(0, pathnames.length)
}

const validateFiles = (pathnames, callback) => {
  (function next(i, len) {
    if (i < len) {
      fs.stat(pathnames[i], (err, stats) => {
        if (err) {
          callback(err)
        } else if (!stats.isFile()) {
          callback(new Error('file allowed'))
        } else {
          next(i + 1, len)
        }
      })
    } else {
      callback(null, pathnames)
    }
    
  })(0, pathnames.length)
}

const main = argv => {
  // 可配置项（比如根路径和端口）
  const { 
    root = '.', 
    port = 80 
  } = JSON.parse(fs.readFileAsync(argv[0], 'utf-8'))
  
  http.createServer((req, res) => {
    const { url } = req;
    const { mime, pathnames } = parseUrl(root, url);

    validateFiles(pathnames, (err, pathnames) => {
      if (err) {
        res.writeHead(404)
        res.end(err.message)
      } else {
        res.writeHead(200, {
          'Content-Type': mime
        })
        outputFiles(pathnames, res)
      }
    })
  }).listen(port)
}

main(process.argv.slice(2))
```



#### 第三次迭代--服务器稳定性优化

从工程角度上讲，没有绝对可靠的系统。即使第二次迭代的代码经过反复检查后能确保没有bug，也很难说是否会因为NodeJS本身，或者是操作系统本身，甚至是硬件本身导致我们的服务器程序在某一天挂掉。`因此一般生产环境下的服务器程序都配有一个守护进程，在服务挂掉的时候立即重启服务。`一般守护进程的代码会远比服务进程的代码简单，从概率上可以保证守护进程更难挂掉。如果再做得严谨一些，甚至守护进程自身可以在自己挂掉时重启自己，从而实现双保险。

因此在本次迭代时，我们先利用NodeJS的进程管理机制，将守护进程作为父进程，将服务器程序作为子进程，并让父进程监控子进程的运行状态，在其异常退出时重启子进程。

> 守护进程的程序实现

```js
// daemon.js
// 通过node daemon.js config.json启动服务，而守护进程会进一步启动和监控服务器进程

const cp = require('child_process');

let worker

function spawn(server, config) {
  worker = cp.spawn('node', [ server, config ])
  worker.on('exit', code => {
    if (code !== 0) {
      spawn(server, config)
    }
  })
}

function main(argv) {
  spawn('server.js', argv[0])
  // 此外，为了能够正常终止服务，我们让守护进程在接收到SIGTERM信号时终止服务器进程
  process.on('SIGTERM', () => {
    worker.kill()
    process.exit(0)
  })
}
```



服务器程序的入口函数也要做相应调整

```js
function main(argv) {
    let server
    
    server = http.createServer((req, res) => {
        ...
    }).listen(port);
    // 在服务器进程这一端，同样在收到SIGTERM信号时先停掉HTTP服务再正常退出。
    process.on('SIGTERM', () => {
        server.close(() => {
            process.exit(0)
        })
    })
}
```



#### 第四次迭代--

在我们解决了服务器本身的功能、性能和可靠性的问题后，接着我们需要考虑一下代码部署的问题，以及服务器控制的问题。

> 设计

一般而言，程序在服务器上有一个固定的部署目录，每次程序有更新后，都重新发布到部署目录里。而一旦完成部署后，一般也可以通过固定的服务控制脚本启动和停止服务。因此我们的服务器程序部署目录可以做如下设计。

```
- deploy/
    - bin/
        startws.sh
        killws.sh
    + conf/
        config.json
    + lib/
        daemon.js
        server.js
```

上面目录结构中，分别存放了服务器控制脚本、配置文件和服务器程序代码。

> 实现

```sh
// startws.sh
// 控制脚本
#!/bin/sh
if [ ! -f "pid" ]
then 
	node ../lib/daemon.js ../conf/config.json &
	echo $! > pid
fi

// killws.sh
#!bin/sh
if [ -f "pid" ]
then 
	kill $(tr -d '\r\n' < pid)
	rm pid
fi
```

